{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process and Translate Speech with Azure AI Services\n",
    "The Azure AI Speech service enables you to build speech-enabled applications. This module focuses on using the speech-to-text and text to speech APIs, which enable you to create apps that are capable of speech recognition and speech synthesis.\n",
    "\n",
    "## Learning objectives\n",
    "In this module, you'll learn how to:\n",
    "\n",
    "- Provision an Azure resource for the Azure AI Speech service\n",
    "- Use the Azure AI Speech to text API to implement speech recognition\n",
    "- Use the Text to speech API to implement speech synthesis\n",
    "- Configure audio format and voices\n",
    "- Use Speech Synthesis Markup Language (SSML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provision an Azure resource for Speech\n",
    "- Make sure you're signed in to the Azure portal at https://portal.azure.com with your Microsoft account.\n",
    "- Create an Azure AI Speech resource in your Azure subscription. You can use either a dedicated Azure AI Speech resource or a multi-service Azure AI Services resource.\n",
    "- Then install the Speech SDK package by running the command below if not already installed.\n",
    "- Install playsound package by running the command below if you don't have it installed already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-cognitiveservices-speech==1.28.0 in /home/niche-4/anaconda3/lib/python3.9/site-packages (1.28.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: playsound in /home/niche-4/anaconda3/lib/python3.9/site-packages (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-cognitiveservices-speech==1.28.0\n",
    "%pip install playsound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Update the `.env` file with your Azure Speech resource key and region.\n",
    "- Run the cell below to import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Import namespaces\n",
    "import azure.cognitiveservices.speech as speech_sdk\n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a speaking Clock app\n",
    "\n",
    "- The main function below performs the following tasks\n",
    "    - Loads environment variables from the .env file\n",
    "    - Creates an instance of the SpeechConfig class, which is used to set the key and region for your Speech resource\n",
    "    - Calls the Transcribe function to transcribe the speech to text\n",
    "    - Calls the TellTime function to get speech output for time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        global speech_config\n",
    "\n",
    "        # Get Configuration Settings\n",
    "        load_dotenv()\n",
    "        cog_key = os.getenv('COG_SERVICE_KEY')\n",
    "        cog_region = os.getenv('COG_SERVICE_REGION')\n",
    "\n",
    "        # Configure speech service\n",
    "        speech_config = speech_sdk.SpeechConfig(cog_key, cog_region)\n",
    "        print('Ready to use speech service in:', speech_config.region)\n",
    "\n",
    "        # Get spoken input\n",
    "        command = TranscribeCommand()\n",
    "        print(command)\n",
    "        if command.lower() == 'what time is it?':\n",
    "            TellTime()\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TranscribeCommand fuction below reads the audio file and transcribes the speech to text. (You can try and replace this with your own audio file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TranscribeCommand():\n",
    "    command = ''\n",
    "    # Configure speech recognition\n",
    "    audioFile = 'time.wav'\n",
    "    playsound(audioFile)\n",
    "    audio_config = speech_sdk.AudioConfig(filename=audioFile)\n",
    "    speech_recognizer = speech_sdk.SpeechRecognizer(speech_config, audio_config)\n",
    "\n",
    "    # Process speech input\n",
    "    speech = speech_recognizer.recognize_once_async().get()\n",
    "    if speech.reason == speech_sdk.ResultReason.RecognizedSpeech:\n",
    "        command = speech.text\n",
    "        print(command)\n",
    "    else:\n",
    "        print(speech.reason)\n",
    "        if speech.reason == speech_sdk.ResultReason.Canceled:\n",
    "            cancellation = speech.cancellation_details\n",
    "            print(cancellation.reason)\n",
    "            print(cancellation.error_details)\n",
    "    # Return the command\n",
    "    return command\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TellTime function below gets the current time and converts it to speech output using the text to speech API.\n",
    "- Call to the main function below run the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use speech service in: eastus\n",
      "What time is it?\n",
      "What time is it?\n",
      "The time is 1:03\n"
     ]
    }
   ],
   "source": [
    "def TellTime():\n",
    "    now = datetime.now()\n",
    "    response_text = 'The time is {}:{:02d}'.format(now.hour,now.minute)\n",
    "\n",
    "    # Configure speech synthesis\n",
    "    speech_config.speech_synthesis_voice_name = \"en-GB-RyanNeural\"\n",
    "    speech_synthesizer = speech_sdk.SpeechSynthesizer(speech_config)\n",
    "\n",
    "    # Synthesize spoken output\n",
    "    speak = speech_synthesizer.speak_text_async(response_text).get()\n",
    "    if speak.reason != speech_sdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(speak.reason)\n",
    "\n",
    "    # Print the response\n",
    "    print(response_text)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate speech with the Azure AI Speech service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create an Azure AI Speech resource in your Azure subscription if not already present.\n",
    "- Install the Speech SDK package by running the command below if not already installed.\n",
    "- Update the `.env` file with your Azure Speech resource key and region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-cognitiveservices-speech==1.24.0\n",
      "  Downloading azure_cognitiveservices_speech-1.24.0-py3-none-manylinux1_x86_64.whl (2.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5 MB 234 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: azure-cognitiveservices-speech\n",
      "  Attempting uninstall: azure-cognitiveservices-speech\n",
      "    Found existing installation: azure-cognitiveservices-speech 1.28.0\n",
      "    Uninstalling azure-cognitiveservices-speech-1.28.0:\n",
      "      Successfully uninstalled azure-cognitiveservices-speech-1.28.0\n",
      "Successfully installed azure-cognitiveservices-speech-1.24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-cognitiveservices-speech==1.24.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run the cell below to import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Import namespaces\n",
    "import azure.cognitiveservices.speech as speech_sdk\n",
    "from playsound import playsound\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main function below performs the following tasks:\n",
    "- Loads environment variables from the .env file\n",
    "- Creates an instance of the SpeechTranslationConfig class, which is used to set the key and region for your Speech resource\n",
    "- Takes target language as input from the user\n",
    "- Creates an instance of the SpeechConfig class, which is used to set the key and region for your Speech resource\n",
    "- Calls the translate function to translate the speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        global speech_config\n",
    "        global translation_config\n",
    "\n",
    "        # Get Configuration Settings\n",
    "        load_dotenv()\n",
    "        cog_key = os.getenv('COG_SERVICE_KEY')\n",
    "        cog_region = os.getenv('COG_SERVICE_REGION')\n",
    "\n",
    "        # Configure translation\n",
    "        translation_config = speech_sdk.translation.SpeechTranslationConfig(cog_key, cog_region)\n",
    "        translation_config.speech_recognition_language = 'en-US'\n",
    "        translation_config.add_target_language('fr')\n",
    "        translation_config.add_target_language('es')\n",
    "        translation_config.add_target_language('hi')\n",
    "        print('Ready to translate from',translation_config.speech_recognition_language)\n",
    "\n",
    "        # Configure speech\n",
    "        speech_config = speech_sdk.SpeechConfig(cog_key, cog_region)\n",
    "\n",
    "        # Get user input\n",
    "        targetLanguage = ''\n",
    "        while targetLanguage != 'quit':\n",
    "            targetLanguage = input('\\nEnter a target language\\n fr = French\\n es = Spanish\\n hi = Hindi\\n Enter anything else to stop\\n').lower()\n",
    "            if targetLanguage in translation_config.target_languages:\n",
    "                Translate(targetLanguage)\n",
    "            else:\n",
    "                targetLanguage = 'quit'\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(ex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Translate function below reads the audio file and translates the speech to text. (You can try and replace this with your own audio file)\n",
    "- It then generates the translated text and speech output in the target language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Translate(targetLanguage):\n",
    "    translation = ''\n",
    "\n",
    "    # Translate speech\n",
    "    audioFile = 'station.wav'\n",
    "    playsound(audioFile)\n",
    "    audio_config = speech_sdk.AudioConfig(filename=audioFile)\n",
    "    translator = speech_sdk.translation.TranslationRecognizer(translation_config, audio_config = audio_config)\n",
    "    print(\"Getting speech from file...\")\n",
    "    result = translator.recognize_once_async().get()\n",
    "    print('Translating \"{}\"'.format(result.text))\n",
    "    translation = result.translations[targetLanguage]\n",
    "    print(translation)\n",
    "\n",
    "\n",
    "    # Synthesize translation\n",
    "    voices = {\n",
    "            \"fr\": \"fr-FR-HenriNeural\",\n",
    "            \"es\": \"es-ES-ElviraNeural\",\n",
    "            \"hi\": \"hi-IN-MadhurNeural\"\n",
    "    }\n",
    "    speech_config.speech_synthesis_voice_name = voices.get(targetLanguage)\n",
    "    speech_synthesizer = speech_sdk.SpeechSynthesizer(speech_config)\n",
    "    speak = speech_synthesizer.speak_text_async(translation).get()\n",
    "    if speak.reason != speech_sdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(speak.reason)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to translate from en-US\n",
      "Getting speech from file...\n",
      "Translating \"Where is the station?\"\n",
      "Où est la gare?\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
